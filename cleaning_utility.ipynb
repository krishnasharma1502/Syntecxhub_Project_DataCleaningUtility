{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94ca229d",
   "metadata": {},
   "source": [
    "# Data Cleaning Utility  \n",
    "Syntecxhub Data Science Internship â€“ Week 1  \n",
    "\n",
    "## Objective\n",
    "Build a reusable data cleaning pipeline that:\n",
    "- Standardizes column names\n",
    "- Converts date columns\n",
    "- Removes duplicates\n",
    "- Handles missing values automatically\n",
    "- Generates a cleaning report\n",
    "- Exports cleaned dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6225a13a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['raw_data.csv']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.listdir(\"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "63569a5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...\n",
      "Dataset loaded successfully!\n",
      "Shape: (9800, 18)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Row ID</th>\n",
       "      <th>Order ID</th>\n",
       "      <th>Order Date</th>\n",
       "      <th>Ship Date</th>\n",
       "      <th>Ship Mode</th>\n",
       "      <th>Customer ID</th>\n",
       "      <th>Customer Name</th>\n",
       "      <th>Segment</th>\n",
       "      <th>Country</th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Postal Code</th>\n",
       "      <th>Region</th>\n",
       "      <th>Product ID</th>\n",
       "      <th>Category</th>\n",
       "      <th>Sub-Category</th>\n",
       "      <th>Product Name</th>\n",
       "      <th>Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>CA-2017-152156</td>\n",
       "      <td>08/11/2017</td>\n",
       "      <td>11/11/2017</td>\n",
       "      <td>Second Class</td>\n",
       "      <td>CG-12520</td>\n",
       "      <td>Claire Gute</td>\n",
       "      <td>Consumer</td>\n",
       "      <td>United States</td>\n",
       "      <td>Henderson</td>\n",
       "      <td>Kentucky</td>\n",
       "      <td>42420.0</td>\n",
       "      <td>South</td>\n",
       "      <td>FUR-BO-10001798</td>\n",
       "      <td>Furniture</td>\n",
       "      <td>Bookcases</td>\n",
       "      <td>Bush Somerset Collection Bookcase</td>\n",
       "      <td>261.9600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>CA-2017-152156</td>\n",
       "      <td>08/11/2017</td>\n",
       "      <td>11/11/2017</td>\n",
       "      <td>Second Class</td>\n",
       "      <td>CG-12520</td>\n",
       "      <td>Claire Gute</td>\n",
       "      <td>Consumer</td>\n",
       "      <td>United States</td>\n",
       "      <td>Henderson</td>\n",
       "      <td>Kentucky</td>\n",
       "      <td>42420.0</td>\n",
       "      <td>South</td>\n",
       "      <td>FUR-CH-10000454</td>\n",
       "      <td>Furniture</td>\n",
       "      <td>Chairs</td>\n",
       "      <td>Hon Deluxe Fabric Upholstered Stacking Chairs,...</td>\n",
       "      <td>731.9400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>CA-2017-138688</td>\n",
       "      <td>12/06/2017</td>\n",
       "      <td>16/06/2017</td>\n",
       "      <td>Second Class</td>\n",
       "      <td>DV-13045</td>\n",
       "      <td>Darrin Van Huff</td>\n",
       "      <td>Corporate</td>\n",
       "      <td>United States</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>California</td>\n",
       "      <td>90036.0</td>\n",
       "      <td>West</td>\n",
       "      <td>OFF-LA-10000240</td>\n",
       "      <td>Office Supplies</td>\n",
       "      <td>Labels</td>\n",
       "      <td>Self-Adhesive Address Labels for Typewriters b...</td>\n",
       "      <td>14.6200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>US-2016-108966</td>\n",
       "      <td>11/10/2016</td>\n",
       "      <td>18/10/2016</td>\n",
       "      <td>Standard Class</td>\n",
       "      <td>SO-20335</td>\n",
       "      <td>Sean O'Donnell</td>\n",
       "      <td>Consumer</td>\n",
       "      <td>United States</td>\n",
       "      <td>Fort Lauderdale</td>\n",
       "      <td>Florida</td>\n",
       "      <td>33311.0</td>\n",
       "      <td>South</td>\n",
       "      <td>FUR-TA-10000577</td>\n",
       "      <td>Furniture</td>\n",
       "      <td>Tables</td>\n",
       "      <td>Bretford CR4500 Series Slim Rectangular Table</td>\n",
       "      <td>957.5775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>US-2016-108966</td>\n",
       "      <td>11/10/2016</td>\n",
       "      <td>18/10/2016</td>\n",
       "      <td>Standard Class</td>\n",
       "      <td>SO-20335</td>\n",
       "      <td>Sean O'Donnell</td>\n",
       "      <td>Consumer</td>\n",
       "      <td>United States</td>\n",
       "      <td>Fort Lauderdale</td>\n",
       "      <td>Florida</td>\n",
       "      <td>33311.0</td>\n",
       "      <td>South</td>\n",
       "      <td>OFF-ST-10000760</td>\n",
       "      <td>Office Supplies</td>\n",
       "      <td>Storage</td>\n",
       "      <td>Eldon Fold 'N Roll Cart System</td>\n",
       "      <td>22.3680</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Row ID        Order ID  Order Date   Ship Date       Ship Mode Customer ID  \\\n",
       "0       1  CA-2017-152156  08/11/2017  11/11/2017    Second Class    CG-12520   \n",
       "1       2  CA-2017-152156  08/11/2017  11/11/2017    Second Class    CG-12520   \n",
       "2       3  CA-2017-138688  12/06/2017  16/06/2017    Second Class    DV-13045   \n",
       "3       4  US-2016-108966  11/10/2016  18/10/2016  Standard Class    SO-20335   \n",
       "4       5  US-2016-108966  11/10/2016  18/10/2016  Standard Class    SO-20335   \n",
       "\n",
       "     Customer Name    Segment        Country             City       State  \\\n",
       "0      Claire Gute   Consumer  United States        Henderson    Kentucky   \n",
       "1      Claire Gute   Consumer  United States        Henderson    Kentucky   \n",
       "2  Darrin Van Huff  Corporate  United States      Los Angeles  California   \n",
       "3   Sean O'Donnell   Consumer  United States  Fort Lauderdale     Florida   \n",
       "4   Sean O'Donnell   Consumer  United States  Fort Lauderdale     Florida   \n",
       "\n",
       "   Postal Code Region       Product ID         Category Sub-Category  \\\n",
       "0      42420.0  South  FUR-BO-10001798        Furniture    Bookcases   \n",
       "1      42420.0  South  FUR-CH-10000454        Furniture       Chairs   \n",
       "2      90036.0   West  OFF-LA-10000240  Office Supplies       Labels   \n",
       "3      33311.0  South  FUR-TA-10000577        Furniture       Tables   \n",
       "4      33311.0  South  OFF-ST-10000760  Office Supplies      Storage   \n",
       "\n",
       "                                        Product Name     Sales  \n",
       "0                  Bush Somerset Collection Bookcase  261.9600  \n",
       "1  Hon Deluxe Fabric Upholstered Stacking Chairs,...  731.9400  \n",
       "2  Self-Adhesive Address Labels for Typewriters b...   14.6200  \n",
       "3      Bretford CR4500 Series Slim Rectangular Table  957.5775  \n",
       "4                     Eldon Fold 'N Roll Cart System   22.3680  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "print(\"Loading dataset...\")\n",
    "\n",
    "df = pd.read_csv(\"data/raw_data.csv\")\n",
    "\n",
    "print(\"Dataset loaded successfully!\")\n",
    "print(\"Shape:\", df.shape)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f9aa66b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of dataset: (9800, 18)\n",
      "\n",
      "Column Names:\n",
      "Index(['Row ID', 'Order ID', 'Order Date', 'Ship Date', 'Ship Mode',\n",
      "       'Customer ID', 'Customer Name', 'Segment', 'Country', 'City', 'State',\n",
      "       'Postal Code', 'Region', 'Product ID', 'Category', 'Sub-Category',\n",
      "       'Product Name', 'Sales'],\n",
      "      dtype='str')\n",
      "\n",
      "Data Types:\n",
      "Row ID             int64\n",
      "Order ID             str\n",
      "Order Date           str\n",
      "Ship Date            str\n",
      "Ship Mode            str\n",
      "Customer ID          str\n",
      "Customer Name        str\n",
      "Segment              str\n",
      "Country              str\n",
      "City                 str\n",
      "State                str\n",
      "Postal Code      float64\n",
      "Region               str\n",
      "Product ID           str\n",
      "Category             str\n",
      "Sub-Category         str\n",
      "Product Name         str\n",
      "Sales            float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of dataset:\", df.shape)\n",
    "print(\"\\nColumn Names:\")\n",
    "print(df.columns)\n",
    "\n",
    "print(\"\\nData Types:\")\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a8a74ced",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing Values:\n",
      "Row ID            0\n",
      "Order ID          0\n",
      "Order Date        0\n",
      "Ship Date         0\n",
      "Ship Mode         0\n",
      "Customer ID       0\n",
      "Customer Name     0\n",
      "Segment           0\n",
      "Country           0\n",
      "City              0\n",
      "State             0\n",
      "Postal Code      11\n",
      "Region            0\n",
      "Product ID        0\n",
      "Category          0\n",
      "Sub-Category      0\n",
      "Product Name      0\n",
      "Sales             0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nMissing Values:\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bbad9d45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated Columns:\n",
      "Index(['row_id', 'order_id', 'order_date', 'ship_date', 'ship_mode',\n",
      "       'customer_id', 'customer_name', 'segment', 'country', 'city', 'state',\n",
      "       'postal_code', 'region', 'product_id', 'category', 'sub-category',\n",
      "       'product_name', 'sales'],\n",
      "      dtype='str')\n"
     ]
    }
   ],
   "source": [
    "# Standardize column names\n",
    "df.columns = df.columns.str.strip().str.lower().str.replace(\" \", \"_\")\n",
    "\n",
    "print(\"Updated Columns:\")\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "709c58d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate rows: 0\n"
     ]
    }
   ],
   "source": [
    "# Check duplicate rows\n",
    "duplicates = df.duplicated().sum()\n",
    "print(\"Number of duplicate rows:\", duplicates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d469284f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "order_date    datetime64[us]\n",
      "ship_date     datetime64[us]\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Convert date columns to datetime\n",
    "df[\"order_date\"] = pd.to_datetime(df[\"order_date\"], errors=\"coerce\")\n",
    "df[\"ship_date\"] = pd.to_datetime(df[\"ship_date\"], errors=\"coerce\")\n",
    "\n",
    "print(df[[\"order_date\", \"ship_date\"]].dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "32869667",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "row_id              0\n",
       "order_id            0\n",
       "order_date       5841\n",
       "ship_date        5985\n",
       "ship_mode           0\n",
       "customer_id         0\n",
       "customer_name       0\n",
       "segment             0\n",
       "country             0\n",
       "city                0\n",
       "state               0\n",
       "postal_code        11\n",
       "region              0\n",
       "product_id          0\n",
       "category            0\n",
       "sub-category        0\n",
       "product_name        0\n",
       "sales               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0fce687a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape after dropping missing dates: (2676, 18)\n",
      "\n",
      "Remaining missing values:\n",
      "row_id           0\n",
      "order_id         0\n",
      "order_date       0\n",
      "ship_date        0\n",
      "ship_mode        0\n",
      "customer_id      0\n",
      "customer_name    0\n",
      "segment          0\n",
      "country          0\n",
      "city             0\n",
      "state            0\n",
      "postal_code      4\n",
      "region           0\n",
      "product_id       0\n",
      "category         0\n",
      "sub-category     0\n",
      "product_name     0\n",
      "sales            0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Drop rows where order_date or ship_date is missing\n",
    "df = df.dropna(subset=[\"order_date\", \"ship_date\"])\n",
    "\n",
    "print(\"Shape after dropping missing dates:\", df.shape)\n",
    "print(\"\\nRemaining missing values:\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b9fe311b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final missing values:\n",
      "row_id           0\n",
      "order_id         0\n",
      "order_date       0\n",
      "ship_date        0\n",
      "ship_mode        0\n",
      "customer_id      0\n",
      "customer_name    0\n",
      "segment          0\n",
      "country          0\n",
      "city             0\n",
      "state            0\n",
      "postal_code      0\n",
      "region           0\n",
      "product_id       0\n",
      "category         0\n",
      "sub-category     0\n",
      "product_name     0\n",
      "sales            0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Fill missing postal_code with median\n",
    "median_postal = df[\"postal_code\"].median()\n",
    "df[\"postal_code\"] = df[\"postal_code\"].fillna(median_postal)\n",
    "\n",
    "print(\"Final missing values:\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c724cb35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------- Cleaning Functions -------- #\n",
    "\n",
    "def standardize_columns(df):\n",
    "    df.columns = df.columns.str.strip().str.lower().str.replace(\" \", \"_\")\n",
    "    return df\n",
    "\n",
    "def convert_dates(df):\n",
    "    for col in df.columns:\n",
    "        if \"date\" in col:\n",
    "            df[col] = pd.to_datetime(df[col], errors=\"coerce\")\n",
    "    return df\n",
    "\n",
    "def remove_duplicates(df):\n",
    "    df = df.drop_duplicates()\n",
    "    return df\n",
    "\n",
    "def handle_missing(df):\n",
    "    # Drop rows with missing date columns\n",
    "    date_cols = [col for col in df.columns if \"date\" in col]\n",
    "    df = df.dropna(subset=date_cols)\n",
    "\n",
    "    # Fill numeric columns with median\n",
    "    numeric_cols = df.select_dtypes(include=np.number).columns\n",
    "    for col in numeric_cols:\n",
    "        df[col] = df[col].fillna(df[col].median())\n",
    "\n",
    "    # Fill categorical columns with mode\n",
    "    categorical_cols = df.select_dtypes(include=\"object\").columns\n",
    "    for col in categorical_cols:\n",
    "        df[col] = df[col].fillna(df[col].mode()[0])\n",
    "\n",
    "    return df\n",
    "\n",
    "def clean_data(df):\n",
    "    df = standardize_columns(df)\n",
    "    df = convert_dates(df)\n",
    "    df = remove_duplicates(df)\n",
    "    df = handle_missing(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fb604737",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape after cleaning: (2676, 18)\n",
      "\n",
      "Missing values after cleaning:\n",
      "row_id           0\n",
      "order_id         0\n",
      "order_date       0\n",
      "ship_date        0\n",
      "ship_mode        0\n",
      "customer_id      0\n",
      "customer_name    0\n",
      "segment          0\n",
      "country          0\n",
      "city             0\n",
      "state            0\n",
      "postal_code      0\n",
      "region           0\n",
      "product_id       0\n",
      "category         0\n",
      "sub-category     0\n",
      "product_name     0\n",
      "sales            0\n",
      "dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\braje\\AppData\\Local\\Temp\\ipykernel_26552\\3234895857.py:28: Pandas4Warning: For backward compatibility, 'str' dtypes are included by select_dtypes when 'object' dtype is specified. This behavior is deprecated and will be removed in a future version. Explicitly pass 'str' to `include` to select them, or to `exclude` to remove them and silence this warning.\n",
      "See https://pandas.pydata.org/docs/user_guide/migration-3-strings.html#string-migration-select-dtypes for details on how to write code that works with pandas 2 and 3.\n",
      "  categorical_cols = df.select_dtypes(include=\"object\").columns\n"
     ]
    }
   ],
   "source": [
    "# Reload raw data\n",
    "raw_df = pd.read_csv(\"data/raw_data.csv\")\n",
    "\n",
    "# Apply cleaning pipeline\n",
    "cleaned_df = clean_data(raw_df)\n",
    "\n",
    "print(\"Shape after cleaning:\", cleaned_df.shape)\n",
    "print(\"\\nMissing values after cleaning:\")\n",
    "print(cleaned_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7e8e0581",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning Report:\n",
      "original_shape: (9800, 18)\n",
      "cleaned_shape: (2676, 18)\n",
      "rows_removed: 7124\n",
      "columns_count: 18\n",
      "missing_values_after_cleaning: 0\n"
     ]
    }
   ],
   "source": [
    "# -------- Generate Cleaning Report -------- #\n",
    "\n",
    "report = {}\n",
    "\n",
    "report[\"original_shape\"] = raw_df.shape\n",
    "report[\"cleaned_shape\"] = cleaned_df.shape\n",
    "report[\"rows_removed\"] = raw_df.shape[0] - cleaned_df.shape[0]\n",
    "report[\"columns_count\"] = cleaned_df.shape[1]\n",
    "report[\"missing_values_after_cleaning\"] = cleaned_df.isnull().sum().sum()\n",
    "\n",
    "print(\"Cleaning Report:\")\n",
    "for key, value in report.items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "db158ca1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files saved successfully.\n"
     ]
    }
   ],
   "source": [
    "# Save cleaned dataset\n",
    "cleaned_df.to_csv(\"cleaned_output/cleaned_data.csv\", index=False)\n",
    "\n",
    "# Save cleaning report\n",
    "with open(\"cleaned_output/cleaning_report.txt\", \"w\") as f:\n",
    "    for key, value in report.items():\n",
    "        f.write(f\"{key}: {value}\\n\")\n",
    "\n",
    "print(\"Files saved successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f7f948",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "A modular cleaning pipeline was developed to automate preprocessing tasks.  \n",
    "The cleaned dataset contains no missing values and is ready for analysis or machine learning workflows."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
